{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SWJk3I6SNJRMP7-iAvg1DYACsIp4nox8",
      "authorship_tag": "ABX9TyNRVFmqo34zwESKu1lUlqhh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PamelaKinga/Templates/blob/main/Read_large_kaggle_data_into_colab_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Large Kaggle Datasets With PySpark in Google Colab / \n",
        "# Initialzing PySpark Google Colab"
      ],
      "metadata": {
        "id": "BGOQwj8A2oUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KtFKNGSUAhif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Pyspark and use it remotely on Google Colabs with a few lines of code**\n",
        "\n",
        "Note: All setup codes below need to be run EACH TIME you want to run PySpark in Google Colab \n",
        "\n",
        "Requires own Kaggle API Token: Account >  API > Create new API. A file named kaggle.json is automatically downloaded. Mount to GDRIVE \n"
      ],
      "metadata": {
        "id": "HWCfmmcZ4xzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6a3X3IBeAfGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Get data from Kaggle by inputting the following codes below \n",
        "\n",
        "**Description:**\n",
        "\n",
        "*   Installs the Kaggle library to be able to use the Kaggle API\n",
        "*   Creates a directory/folder called .kaggle in the root \n",
        "directory\n",
        "* Copies the kaggle.json saved in personal g-drive to the new directory created above. "
      ],
      "metadata": {
        "id": "EdzmpLl9_anE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okUfnSpDxc3p"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy API Command from each dataset and replace line 18 as: ! {input API command}"
      ],
      "metadata": {
        "id": "PrqcPtVa_iV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d mkechinov/ecommerce-behavior-data-from-multi-category-store\n",
        "! unzip ecommerce-behavior-data-from-multi-category-store.zip"
      ],
      "metadata": {
        "id": "1W0lQFbp_l30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2. Install PySpark dependencies\n",
        "\n",
        "**Description:** Dependencies include Java 8, Apache spark with Hadoop, and FindSpark"
      ],
      "metadata": {
        "id": "ek77AHiv_ocM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "! wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "! tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "! pip install -q findspark"
      ],
      "metadata": {
        "id": "bHo4ipOdy9vZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  3. Next is to set the environment path that enables us to run PySpark in our Colab environment by setting the location of Java and Spark"
      ],
      "metadata": {
        "id": "rIEKRx56_5uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "AAzqxUcH2Hmf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  4. Finally, run a local spark session to test installation"
      ],
      "metadata": {
        "id": "P9NAWt1tAOkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark"
      ],
      "metadata": {
        "id": "PfloLIfg4Nua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  5. Ready to start analyzing table in PySpark!"
      ],
      "metadata": {
        "id": "oy9ysm0ZAV6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('2019*.csv', header=True, sep=\",\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "xz4vvACx4Vii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Attribution: Okoh Anita from: https://medium.com/towards-artificial-intelligence/reading-large-kaggle-dataset-with-pyspark-in-google-colab-41aebb7a89c8\n",
        "\n",
        "Copied as a colab notebook in personal environment to reuse\n"
      ],
      "metadata": {
        "id": "z1qdEsLUAlHz"
      }
    }
  ]
}